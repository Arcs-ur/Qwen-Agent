import csv
import json
import logging
import os
import subprocess
from datetime import datetime
from typing import Dict, List, Union, Iterator
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
import re
import time
# --- å¯¼å…¥ Qwen-Agent ç›¸å…³æ¨¡å— ---
from qwen_agent.agents import Assistant
from qwen_agent.llm import get_chat_model
from qwen_agent.llm.schema import Message
from qwen_agent.tools.base import BaseTool
from qwen_agent.gui import WebUI

# --- 1. å…¨å±€é…ç½® ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
WORKSPACE = os.path.join(os.getcwd(), 'workspace/doc')
os.makedirs(os.path.join(WORKSPACE, 'reports'), exist_ok=True)
os.makedirs(os.path.join(WORKSPACE, 'debug'), exist_ok=True)


# --- 2. æ ¸å¿ƒå·¥å…·ç±» (ä¸ä¹‹å‰ç›¸åŒ) ---
# TrivyScanner, JsonToCsvConverter, CVEClassifier, CVEReportGenerator è¿™å››ä¸ªç±»çš„ä»£ç 
# å’Œæˆ‘ä»¬ä¹‹å‰ç‰ˆæœ¬å®Œå…¨ä¸€æ ·ï¼Œè¿™é‡Œä¸ºäº†ç®€æ´å…ˆæŠ˜å èµ·æ¥ï¼Œæ‚¨ç›´æ¥ä½¿ç”¨ä¸Šä¸€ç‰ˆæœ¬å³å¯ã€‚
# (åœ¨ä¸‹é¢çš„å®Œæ•´ä»£ç å—ä¸­æˆ‘ä¼šå…¨éƒ¨å±•å¼€)

class TrivyScanner(BaseTool):
    name = "trivy_scanner"
    description = "Runs a Trivy vulnerability scan on a Docker image and saves the output as a JSON file."
    parameters = [{'name': 'image_name', 'type': 'string', 'description': 'The full name of the Docker image to scan (e.g., \'python:3.9-slim\')', 'required': True}]
    def call(self, params: Union[str, dict], **kwargs) -> str:
        try:
            params = self._verify_json_format_args(params)
            image_name = params['image_name']
        except Exception as e: return f'{{"error": "Parameter error: {e}"}}'
        sanitized_name = image_name.replace(':', '_').replace('/', '_')
        output_path = os.path.join(WORKSPACE, f'{sanitized_name}_cves.json')
        command = ['trivy', 'image', '--format', 'json', '--output', output_path, image_name]
        logging.info(f"Running Trivy scan for {image_name}...")
        try:
            subprocess.run(command, check=True, capture_output=True, text=True)
            success_message = f"Successfully scanned image '{image_name}'. Results saved to: {output_path}"
            logging.info(success_message)
            return json.dumps({"output_path": output_path})
        except FileNotFoundError: return '{{"error": "Trivy command not found. Please ensure Trivy is installed."}}'
        except subprocess.CalledProcessError as e: return f'{{"error": "Trivy scan failed for \'{image_name}\'. Stderr: {e.stderr}"}}'

class JsonToCsvConverter(BaseTool):
    name = "json_to_csv_converter"
    description = "Converts a Trivy JSON report file to a CSV file."
    parameters = [{'name': 'json_file_path', 'type': 'string', 'description': 'The path to the input JSON file from a Trivy scan.', 'required': True}]
    def call(self, params: Union[str, dict], **kwargs) -> str:
        try:
            params = self._verify_json_format_args(params)
            json_file_path = params['json_file_path']
        except Exception as e: return f'{{"error": "Parameter error: {e}"}}'
        if not os.path.exists(json_file_path): return f'{{"error": "Input file not found at {json_file_path}"}}'
        csv_file_path = json_file_path.replace('.json', '.csv')
        headers = ["VulnerabilityID", "PkgName", "InstalledVersion", "FixedVersion", "Severity", "Title", "Description", "PrimaryURL"]
        try:
            with open(json_file_path, 'r', encoding='utf-8') as f_json, open(csv_file_path, 'w', encoding='utf-8', newline='') as f_csv:
                writer = csv.DictWriter(f_csv, fieldnames=headers)
                writer.writeheader()
                data = json.load(f_json)
                if 'Results' not in data: return json.dumps({"output_path": csv_file_path, "status": "empty"})
                for result in data.get('Results', []):
                    for vuln in result.get('Vulnerabilities', []): writer.writerow({h: str(vuln.get(h, "")).replace('\n', ' ') for h in headers})
            logging.info(f"Successfully converted {json_file_path} to {csv_file_path}")
            return json.dumps({"output_path": csv_file_path})
        except Exception as e: return f'{{"error": "Error during JSON to CSV conversion: {e}"}}'

class CVEClassifier(BaseTool):
    name = "cve_classifier"
    description = "Reads two CVE CSV reports (target and base), classifies the vulnerabilities."
    parameters = [{'name': 'target_csv_path', 'type': 'string', 'required': True}, {'name': 'base_csv_path', 'type': 'string', 'required': True}]
    def call(self, params: Union[str, dict], **kwargs) -> Dict:
        # ... (å†…éƒ¨é€»è¾‘å’Œä¹‹å‰ç‰ˆæœ¬å®Œå…¨ä¸€æ ·) ...
        try:
            params = self._verify_json_format_args(params)
            target_csv_path, base_csv_path = params['target_csv_path'], params['base_csv_path']
        except Exception as e: return {"error": f"Parameter error: {e}"}
        def read_cves_from_csv(file_path: str) -> Dict[str, dict]:
            cves = {}
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    reader = csv.DictReader(f)
                    for row in reader:
                        if cve_id := row.get("VulnerabilityID"): cves[cve_id] = row
            except FileNotFoundError: return {}
            return cves
        target_cves, base_cves = read_cves_from_csv(target_csv_path), read_cves_from_csv(base_csv_path)
        base_cve_ids = set(base_cves.keys())
        target_cve_ids = set(target_cves.keys())
        type1_cves, type2_cves, type3_cves = [], [], []
        for cve_id, cve_data in target_cves.items():
            if not cve_data.get("FixedVersion"): type1_cves.append(cve_data)
            elif cve_id in base_cve_ids: type2_cves.append(cve_data)
            else: type3_cves.append(cve_data)

        summary = (
            f"Successfully classified CVEs. "
            f"base_cve_num{len(base_cve_ids)}"
            f"target_cve_num{len(target_cve_ids)}"
            f"Found {len(type1_cves)} Type-1, "
            f"{len(type2_cves)} Type-2, and "
            f"{len(type3_cves)} Type-3 vulnerabilities for analysis."
        )
        logging.info(summary)
        
        return {"type1_cves": type1_cves, "type2_cves": type2_cves, "type3_cves_to_analyze": type3_cves}

class CVEReportGenerator(BaseTool):
    name = "cve_report_generator"
    description = "Generates trivyignore YAML files and a suggestion report from classified CVE lists."
    parameters = [{'name': 'classified_cves', 'type': 'dict', 'required': True}]
    def call(self, params: Union[str, dict], **kwargs) -> str:
        # ... (å†…éƒ¨é€»è¾‘å’Œä¹‹å‰ç‰ˆæœ¬å®Œå…¨ä¸€æ ·) ...
        """ä¸ºæ¯ä¸€ç±» CVE ç”Ÿæˆç‹¬ç«‹çš„ trivyignore æ–‡ä»¶å’Œæœ€ç»ˆçš„å»ºè®®æŠ¥å‘Š"""
        try:
            cves_data = self._verify_json_format_args(params).get('classified_cves', {})
            # ... (çœç•¥äº†å†™å…¥æ–‡ä»¶çš„è¯¦ç»†ä»£ç , å’Œä¹‹å‰ä¸€æ ·) ...
            def _write_ignore_file(file_path: Path, ignore_list: List[Dict], header: str):
                if not ignore_list: return 0
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(f"# {header}\n# Auto-generated by Qwen-Agent\n")
                    f.write("vulnerabilities:\n")
                    for entry in ignore_list:
                        f.write(f"- id: {entry['id']}\n")
                        if entry.get('url'): f.write(f"  url: {entry['url']}\n")
                        f.write(f"  statement: {entry['reason']}\n")
                return len(ignore_list)
            
            type1_ignores = [{'id': c.get('VulnerabilityID', ''), 'url':c.get('PrimaryURL',''), 'reason': "There is currently no recommended version available to fix this vulnerability. We will continue to monitor for updates and apply a fix once it is released."} for c in cves_data.get('type1_cves', [])]
            count1 = _write_ignore_file(Path(WORKSPACE)/'trivyignore-type1.yaml', type1_ignores, "There is currently no recommended version available to fix this vulnerability. We will continue to monitor for updates and apply a fix once it is released.")

            type2_ignores = [{'id': c.get('VulnerabilityID', ''), 'url':c.get('PrimaryURL',''), 'reason': "The affected package is not used directly by our application. It comes from the underlying base image. We will continue to monitor and adopt a newer base image if one becomes available that resolves this issue."} for c in cves_data.get('type2_cves', [])]
            count2 = _write_ignore_file(Path(WORKSPACE)/'trivyignore-type2.yaml', type2_ignores, "The affected package is not used directly by our application. It comes from the underlying base image. We will continue to monitor and adopt a newer base image if one becomes available that resolves this issue.")

            type3_results = cves_data.get('type3_results', [])

            type3_ignores = [{'id': i.get('cve', {}).get('VulnerabilityID'), 'url': i.get('cve', {}).get('PrimaryURL'), 'reason': f"{i.get('analysis', {}).get('analysis', 'N/A')}"} for i in type3_results]
            count3 = _write_ignore_file(Path(WORKSPACE)/'trivyignore-type3.yaml', type3_ignores, "Analyzed by agent.")

            suggestions = [f"[{i.get('cve', {}).get('VulnerabilityID')}/{i.get('cve', {}).get('PkgName')}]: {i.get('analysis', {}).get('suggestion')}" for i in type3_results if i.get('analysis', {}).get('suggestion')]
            report_path = Path(WORKSPACE)/'reports'/'upgrade_patch_suggestions.txt'
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write("Suggestions from Type-3 Analysis\n" + "="*50 + "\n")
                if suggestions: f.writelines(f"{s}\n\n" for s in suggestions)
                else: f.write("No actionable suggestions were generated.\n")
            
            return (f"æŠ¥å‘Šç”Ÿæˆå®Œæˆã€‚\n" f"- {count1}æ¡Type-1è§„åˆ™ -> trivyignore-type1.yaml\n" f"- {count2}æ¡Type-2è§„åˆ™ -> trivyignore-type2.yaml\n" f"- {count3}æ¡Type-3è§„åˆ™ -> trivyignore-type3.yaml\n" f"- {len(suggestions)}æ¡å»ºè®® -> {report_path}")
        except Exception as e:
            return f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}"

# --- 3. ä¸“å®¶ä»£ç†çš„æŒ‡ä»¤å’Œã€ä¿®å¤åã€‘çš„å¤„ç†å‡½æ•° ---

# TYPE3_ANALYST_PROMPT = """You are a senior cybersecurity analyst. Your ONLY task is to analyze the provided CVE JSON data.
# Respond with a SINGLE JSON object containing your analysis. Do not add any text before or after the JSON.
# The JSON object must have this exact structure:
# {"analysis": {"action": "ignore" | "suggest_patch", "reason": "...", "suggestion": "..." | null}}"""

def call_llm_for_analysis(cve_data: dict, llm) -> dict:

    prompt = f"""
    è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹JSONæ ¼å¼åˆ†æCVEæ¼æ´ï¼š
    {{
        "risk_level": "é«˜/ä¸­/ä½",
        "analysis": "å½±å“åˆ†æ, æ˜¯å¦ä¼šå½±å“åˆ°è¢«åˆ†æé•œåƒçš„ä½¿ç”¨ç­‰",
        "suggestion": "ä¿®å¤å»ºè®®",
        "workaround": "ä¸´æ—¶è§£å†³æ–¹æ¡ˆ(å¦‚æ— åˆ™ç•™ç©º)"
    }}

    å¾…åˆ†æCVEè¯¦æƒ…ï¼š
    CVE ID: {cve_data.get('VulnerabilityID', 'N/A')}
    è½¯ä»¶åŒ…: {cve_data.get('PkgName', 'N/A')} 
    ç‰ˆæœ¬: {cve_data.get('InstalledVersion', 'N/A')}
    ä¿®å¤ç‰ˆæœ¬: {cve_data.get('FixedVersion', 'æš‚æ— ')}
    ä¸¥é‡ç¨‹åº¦: {cve_data.get('Severity', 'N/A')}
    æè¿°: {cve_data.get('Description', 'æ— æè¿°ä¿¡æ¯')}
    """

    max_retries = 5
    retry_delay = 1.5  # é€‚å½“å¢åŠ å»¶è¿Ÿ
    
    for attempt in range(max_retries):
        try:
            # 1. è°ƒç”¨API
            response = llm.chat(
                messages=[{'role': 'user', 'content': prompt}],
                stream=False
            )
            
            # 2. éªŒè¯å“åº”æ ¼å¼
            if not (isinstance(response, list) and 
                   len(response) > 0 and 
                   isinstance(response[0], dict) and
                   'content' in response[0]):
                raise ValueError("å“åº”æ ¼å¼ä¸ç¬¦åˆé¢„æœŸ")
            
            # 3. æå–JSONå†…å®¹
            content = response[0]['content']
            json_str = re.search(r'```json\n(.*?)\n```', content, re.DOTALL)
            
            if not json_str:
                # å°è¯•ç›´æ¥è§£ææ•´ä¸ªcontent
                try:
                    analysis = json.loads(content)
                except json.JSONDecodeError:
                    raise ValueError("æœªæ‰¾åˆ°æœ‰æ•ˆçš„JSONå†…å®¹")
            else:
                analysis = json.loads(json_str.group(1))
            
            # 4. éªŒè¯å¿…éœ€å­—æ®µ
            required_fields = ["risk_level", "analysis", "suggestion"]
            for field in required_fields:
                if field not in analysis:
                    raise ValueError(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
            print(analysis)
            return {
                "cve": cve_data,
                "analysis": analysis
            }
            
        except Exception as e:
            logging.warning(f"å°è¯• {attempt + 1}/{max_retries} å¤±è´¥ (CVE-{cve_data.get('VulnerabilityID')}): {str(e)}")
            if attempt < max_retries - 1:
                time.sleep(retry_delay * (attempt + 1))
                continue
            
            return {
                "cve": cve_data,
                "analysis": {
                    "error": f"åˆ†æå¤±è´¥: {str(e)}",
                    "raw_response": response[0]['content'][:500] if isinstance(response, list) and len(response) > 0 else str(response)[:500]
                }
            }

# --- 4. [æ–°æ¶æ„] ä¸“ä¸ºWebUIè®¾è®¡çš„ CVEå·¥ä½œæµå·¥å…· ---

class CVEWorkflowTool(BaseTool):
    name = "cve_workflow_tool"
    description = "ä¸ºæŒ‡å®šçš„Dockeré•œåƒå¯åŠ¨ä¸€ä¸ªå®Œæ•´çš„CVEåˆ†æå·¥ä½œæµï¼ŒåŒ…æ‹¬æ‰«æã€åˆ†ç±»ã€AIåˆ†æå’ŒæŠ¥å‘Šç”Ÿæˆã€‚"
    parameters = [
        {'name': 'target_image', 'type': 'string', 'description': 'éœ€è¦åˆ†æçš„ç›®æ ‡é•œåƒ, e.g., \'nginx:1.14.2-alpine\'', 'required': True},
        {'name': 'base_image', 'type': 'string', 'description': 'ç”¨äºå¯¹æ¯”çš„åŸºç¡€é•œåƒ, e.g., \'debian:stretch-slim\'', 'required': True}
    ]
    
    def __init__(self, llm):
        super().__init__()
        self.llm = llm
        self.scanner = TrivyScanner()
        self.converter = JsonToCsvConverter()
        self.classifier = CVEClassifier()
        self.reporter = CVEReportGenerator()
    
    def call(self, params: Union[str, dict], **kwargs) -> str:
        """
        ä¿®æ”¹åçš„callæ–¹æ³•è¿”å›å­—ç¬¦ä¸²è€Œä¸æ˜¯ç”Ÿæˆå™¨ï¼Œä½†é€šè¿‡kwargs['messages']ä¼ é€’å®æ—¶æ›´æ–°
        """
        try:
            params = self._verify_json_format_args(params)
            target_image = params['target_image']
            base_image = params['base_image']
        except Exception as e:
            return f"âŒ å‚æ•°é”™è¯¯: {e}"
        
        # è·å–æ¶ˆæ¯å›è°ƒå‡½æ•°ï¼ˆç”¨äºå®æ—¶æ›´æ–°ï¼‰
        message_callback = kwargs.get('messages', None)
        
        def _send_update(msg: str):
            """è¾…åŠ©å‡½æ•°ï¼šå‘é€æ›´æ–°æ¶ˆæ¯"""
            if callable(message_callback):
                message_callback(msg)
        
        _send_update(f"ğŸš€ **å·¥ä½œæµå¯åŠ¨**\n   - ç›®æ ‡é•œåƒ: `{target_image}`\n   - åŸºç¡€é•œåƒ: `{base_image}`")
        
        try:
            # --- æ­¥éª¤ 1 & 2: æ‰«æå’Œè½¬æ¢ ---
            _send_update("\n---\n**æ­¥éª¤ 1/5: æ‰«æé•œåƒä¸­...** ğŸ”")
            target_scan_res = json.loads(self.scanner.call({'image_name': target_image}))
            if 'error' in target_scan_res: raise RuntimeError(target_scan_res['error'])
            base_scan_res = json.loads(self.scanner.call({'image_name': base_image}))
            if 'error' in base_scan_res: raise RuntimeError(base_scan_res['error'])
            
            _send_update(f"   - âœ… æ‰«æå®Œæˆ: `{target_scan_res['output_path']}`")
            _send_update("\n---\n**æ­¥éª¤ 2/5: è½¬æ¢æŠ¥å‘Šä¸ºCSV...** ğŸ“„")
            target_csv_res = json.loads(self.converter.call({'json_file_path': target_scan_res['output_path']}))
            if 'error' in target_csv_res: raise RuntimeError(target_csv_res['error'])
            base_csv_res = json.loads(self.converter.call({'json_file_path': base_scan_res['output_path']}))
            if 'error' in base_csv_res: raise RuntimeError(base_csv_res['error'])
            _send_update(f"   - âœ… è½¬æ¢å®Œæˆ: `{target_csv_res['output_path']}`")
            
            # --- æ­¥éª¤ 3: åˆ†ç±» ---
            _send_update("\n---\n**æ­¥éª¤ 3/5: å¯¹æ¯”å¹¶åˆ†ç±»CVE...** ğŸ—‚ï¸")
            classification_result = self.classifier.call({
                'target_csv_path': target_csv_res['output_path'],
                'base_csv_path': base_csv_res['output_path']
            })
            if 'error' in classification_result: raise RuntimeError(classification_result['error'])
            
            type1_cves = classification_result.get('type1_cves', [])
            type2_cves = classification_result.get('type2_cves', [])
            type3_cves = classification_result.get('type3_cves_to_analyze', [])
            _send_update(f"   - âœ… åˆ†ç±»å®Œæˆ: å‘ç°Type-1: {len(type1_cves)}, Type-2: {len(type2_cves)}, Type-3: {len(type3_cves)}")
            
            # --- æ­¥éª¤ 4: å¹¶è¡ŒAIåˆ†æ ---
            # åœ¨ CVEWorkflowTool.call() æ–¹æ³•ä¸­ä¿®æ”¹å¹¶è¡Œå¤„ç†éƒ¨åˆ†ï¼š
            # åœ¨CVEWorkflowToolä¸­
            _send_update(f"\n---\n**æ­¥éª¤ 4/5: ä¸“ä¸šåˆ†æ {len(type3_cves)} ä¸ªå…³é”®æ¼æ´...** ğŸ”")
            type3_analysis_results = []

            if type3_cves:
                # ç²¾ç¡®æ§åˆ¶è¯·æ±‚é€Ÿç‡
                max_concurrent = 2  # è¿›ä¸€æ­¥é™ä½å¹¶å‘æ•°
                request_interval = 2.0  # è¯·æ±‚é—´éš”2ç§’
                
                with ThreadPoolExecutor(max_workers=max_concurrent) as executor:
                    futures = []
                    for i, cve in enumerate(type3_cves):
                        futures.append(executor.submit(
                            call_llm_for_analysis, 
                            cve, 
                            self.llm
                        ))
                        
                        # å®æ—¶è¿›åº¦æ›´æ–°
                        _send_update(f"   - å·²æäº¤: {cve.get('VulnerabilityID')} ({i+1}/{len(type3_cves)})")
                        
                        if i < len(type3_cves) - 1:  # æœ€åä¸€ä¸ªä¸éœ€è¦sleep
                            time.sleep(request_interval)
                    
                    # å¤„ç†ç»“æœ
                    success_count = 0
                    for future in as_completed(futures):
                        result = future.result()
                        type3_analysis_results.append(result)
                        
                        if "error" not in result["analysis"]:
                            success_count += 1
                            status = "âœ…"
                        else:
                            status = f"âš ï¸({result['analysis']['error']})"
                        
                        cve_id = result['cve'].get('VulnerabilityID')
                        _send_update(f"   - å®Œæˆ: {cve_id} {status}")
                
                # æœ€ç»ˆç»Ÿè®¡
                _send_update(f"\nåˆ†æå®Œæˆ: {success_count}æˆåŠŸ, {len(type3_cves)-success_count}å¤±è´¥")
            _send_update("   - âœ… å…¨éƒ¨Type-3æ¼æ´åˆ†æå®Œæˆ!")
            
            # --- æ­¥éª¤ 5: ç”ŸæˆæŠ¥å‘Š ---
            _send_update("\n---\n**æ­¥éª¤ 5/5: ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šå’Œå¿½ç•¥æ–‡ä»¶...** ğŸ“")
            final_report_data = {
                "type1_cves": type1_cves,
                "type2_cves": type2_cves,
                "type3_results": type3_analysis_results
            }
            final_status = self.reporter.call({'classified_cves': final_report_data})
            
            return f"\n---\nâœ… **å·¥ä½œæµå…¨éƒ¨å®Œæˆ!**\n\n```text\n{final_status}\n```"
            
        except Exception as e:
            logging.error(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            return f"\nâŒ **å·¥ä½œæµæ‰§è¡Œå¤±è´¥**: {e}"

# --- 5. ä¸»ç¨‹åºå…¥å£ ---
def main():
    # --- LLM é…ç½® ---
    llm_config = {
        'model': 'Qwen/Qwen3-Coder-480B-A35B-Instruct',
        'model_server': 'https://api-inference.modelscope.cn/v1',
        'api_key': 'ms-df44f694-9197-4fff-beaf-677b6bdc5e1b' # è¯·æ›¿æ¢ä¸ºæ‚¨çš„ ModelScope API Key
    }
    llm = get_chat_model(llm_config)

    # --- åˆ›å»ºä¸»äº¤äº’ä»£ç† ---
    # è¿™ä¸ªä»£ç†å¾ˆç®€å•ï¼Œå®ƒçš„ä»»åŠ¡å°±æ˜¯ç†è§£ç”¨æˆ·æ„å›¾ï¼Œå¹¶è°ƒç”¨æˆ‘ä»¬çš„ CVEWorkflowTool
    system_prompt = """
    You are an intelligent cybersecurity assistant. Your mission is to automate the processing of CVE vulnerabilities in a Docker image.
    You must strictly follow these steps and call the tools in sequence:
    1.  **Scan Images**: Use the `trivy_scanner` tool to scan the user-provided target image and base image. This will produce two JSON files.
    2.  **Convert Reports**: Use the `json_to_csv_converter` tool for each of the two JSON files to convert them into CSV format.
    3.  **Classify CVEs**: Call the `cve_classifier` tool ONCE, passing the file paths of the two CSVs you just created. This tool will do the classification and return structured data containing lists of 'type1_cves', 'type2_cves', and 'type3_cves_to_analyze'.
    4.  **Analyze Type-3 CVEs**: The previous step gave you a list of Type-3 CVEs. Now, you must act as a security expert. For EACH AND EVERY CVE in the 'type3_cves_to_analyze' list, generate a JSON object with your analysis. The format for each analysis must be: `{"cve": {... a dict containing the original CVE data ...}, "analysis": {"action": "ignore" | "suggest_patch", "reason": "...determine whether the CVE is relevant to the image,if not, the image not impacted by this issue,if yes, give the reason and some details...", "suggestion": "..." | null}}`.
    5.  **Generate Final Report**: After analyzing all Type-3 CVEs, call the `cve_report_generator` tool exactly ONCE. You will construct its `classified_cves` parameter as follows:
        - The 'type1_cves' key should contain the list of Type-1 CVEs from step 3.
        - The 'type2_cves' key should contain the list of Type-2 CVEs from step 3.
        - The 'type3_results' key should contain the list of your analysis JSON objects from step 4.
    6.  **Conclude**: After the report is generated successfully, inform the user that the task is complete and state the location of the output files.
    """

    # å°†llmå®ä¾‹ä¼ å…¥æˆ‘ä»¬çš„å¤§å·¥å…·
    cve_tool = CVEWorkflowTool(llm=llm)
    tool_list = [
        cve_tool,
        {
            'mcpServers': {  # You can specify the MCP configuration file
                'time': {
                    'command': 'uvx',
                    'args': ['mcp-server-time', '--local-timezone=Asia/Shanghai'],
                    'env':{
                        "http_proxy": "http://proxy.iil.intel.com:911",
                        "https_proxy": "http://proxy.iil.intel.com:911"
                    }
                },
                'fetch': {
                    'command': 'uvx',
                    'args': ['mcp-server-fetch'],
                    'env':{
                        "http_proxy": "http://proxy.iil.intel.com:911",
                        "https_proxy": "http://proxy.iil.intel.com:911"
                    }
                },
                "memory": {
                    "command": "npx",
                    "args": ["-y", "@modelcontextprotocol/server-memory"],
                    'env':{
                        "http_proxy": "http://proxy.iil.intel.com:911",
                        "https_proxy": "http://proxy.iil.intel.com:911"
                    }
                },
                "sqlite" : {
                    "command": "uvx",
                    "args": [
                        "mcp-server-sqlite",
                        "--db-path",
                        "test.db"
                    ],
                    'env':{
                        "http_proxy": "http://proxy.iil.intel.com:911",
                        "https_proxy": "http://proxy.iil.intel.com:911"
                    }
                },
                # "Trivy MCP": {
                #     "command": "/home/intel/cengguang/trivy",
                #     "args": [
                #         "mcp",  
                #         "--trivy-binary",  
                #         "/home/intel/cengguang/trivy",  
                #         "-t",  
                #         "stdio",  
                #         "-p",  
                #         "23456"  
                #     ],
                #     'env':{
                #         "http_proxy": "http://proxy.iil.intel.com:911",
                #         "https_proxy": "http://proxy.iil.intel.com:911"
                #     }
                # },
                "filesystem": {
                    "command": "docker",
                    "args": [
                        "run",
                        "-i",
                        "--rm",
                        "--mount", "type=bind,src=/tmp,dst=/tmp",
                        "--mount", "type=bind,src=/home/intel/chennan,dst=/home/intel/chennan",
                        "mcp/filesystem",
                        "/home/intel/chennan"
                    ],
                    'env':{
                        "http_proxy": "http://proxy.iil.intel.com:911",
                        "https_proxy": "http://proxy.iil.intel.com:911"
                    }
                },
            }
        }
    ]
    # åˆ›å»ºUIä»£ç†
    agent = Assistant(
        llm=llm,
        function_list=tool_list,
        system_message=system_prompt
    )

    # --- å¯åŠ¨WebUI ---
    # é¢„è®¾ä¸€äº›ç”¨æˆ·å¯èƒ½ç‚¹å‡»çš„ç¤ºä¾‹é—®é¢˜
    chatbot_config = {
        'prompt.suggestions': [
            'ä½ å¥½',
            'è¯·å¸®æˆ‘åˆ†æä¸€ä¸‹é•œåƒ nginx:1.14.2-alpineï¼Œå®ƒçš„åŸºç¡€é•œåƒæ˜¯ debian:stretch-slim'
        ],
        'verbose': True
    }
    WebUI(agent, chatbot_config=chatbot_config).run()

if __name__ == '__main__':
    main()